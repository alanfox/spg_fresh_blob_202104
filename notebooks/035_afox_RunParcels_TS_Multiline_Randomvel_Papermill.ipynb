{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcels Experiment:<br><br>Expanding the polyline code to release particles at density based on local velocity normal to section.\n",
    "\n",
    "_(Based on an experiment originally designed by Christina Schmidt.)_\n",
    "\n",
    "_(Runs on GEOMAR Jupyter Server at https://schulung3.geomar.de/user/workshop007/lab)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "- Check/ask how OceanParcels deals with partial cells, if it does.\n",
    "    - It doesn't. Does it matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from parcels import (\n",
    "    AdvectionRK4_3D,\n",
    "    ErrorCode,\n",
    "    FieldSet,\n",
    "    JITParticle,\n",
    "    ParticleSet,\n",
    "    Variable\n",
    ")\n",
    "\n",
    "# from operator import attrgetter\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean as co\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# import dask as dask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment settings (user input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "These can be set in papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# OSNAP multiline details\n",
    "sectionPathname = '../data'\n",
    "sectionFilename = 'osnap_pos_wp.txt'\n",
    "sectionname = 'osnap'\n",
    "# location of input data\n",
    "path_name = '/data/iAtlantic/data/'\n",
    "experiment_name = 'VIKING20X.L46-KKG36107B' \n",
    "data_resolution = '1m'\n",
    "# location of mask data\n",
    "mask_path_name = '/data/iAtlantic/mask/'\n",
    "mesh_mask_filename = '1_mesh_mask.nc_notime_depthw'\n",
    "# location of output data\n",
    "outpath_name = '../data_output/'\n",
    "\n",
    "year_prefix = 201  # this does from 2000 onwards\n",
    "\n",
    "# set line segment to use\n",
    "start_vertex = 4\n",
    "end_vertex = 12\n",
    "\n",
    "# experiment duration etc\n",
    "runtime_in_days = 100\n",
    "dt_in_minutes = -10\n",
    "# repeatdt = timedelta(days=3)\n",
    "\n",
    "# number of particles to track\n",
    "create_number_particles = 200000  # many will not be ocean points\n",
    "use_number_particles = 200000\n",
    "\n",
    "min_release_depth = 0\n",
    "max_release_depth = 500  \n",
    "\n",
    "# max current speed for particle selection\n",
    "max_current = 1.0\n",
    "\n",
    "# set base release date and time\n",
    "t_0_str = '2010-01-16T12:00:00'\n",
    "t_start_str = '2016-01-16T12:00:00'\n",
    "\n",
    "# particle positions are stored every x hours \n",
    "outputdt_in_hours = 120\n",
    "\n",
    "# select subdomain (to decrease needed resources) comment out to use whole domain\n",
    "# sd_i1, sd_i2 = 0, 2404  # western/eastern limit (indices not coordinates)\n",
    "# sd_j1, sd_j2 = 1200, 2499  # southern/northern limit (indices not coordinates)\n",
    "# sd_z1, sd_z2 = 0, 46\n",
    "\n",
    "# how to initialize the random number generator\n",
    "RNG_seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times\n",
    "t_0 = datetime.fromisoformat(t_0_str)  # using monthly mean fields. Check dates.\n",
    "t_start = datetime.fromisoformat(t_start_str)\n",
    "\n",
    "# names of files to load \n",
    "fname_U = f'1_{experiment_name}_{data_resolution}_{year_prefix}*_grid_U.nc'  \n",
    "fname_V = f'1_{experiment_name}_{data_resolution}_{year_prefix}*_grid_V.nc'\n",
    "fname_T = f'1_{experiment_name}_{data_resolution}_{year_prefix}*_grid_T.nc'\n",
    "fname_W = f'1_{experiment_name}_{data_resolution}_{year_prefix}*_grid_W.nc_repaire_depthw_time'\n",
    "\n",
    "sectionPath = Path(sectionPathname)\n",
    "\n",
    "data_path = Path(path_name)\n",
    "\n",
    "mask_path = Path(mask_path_name)\n",
    "\n",
    "outpath = Path(outpath_name)\n",
    "\n",
    "display(t_0)\n",
    "display(t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dt_in_minutes > 0:\n",
    "    direction = '_forwards_'\n",
    "else:\n",
    "    direction = '_backward_'\n",
    "\n",
    "year_str = str(t_start.year)\n",
    "month_str = str(t_start.month).zfill(2)\n",
    "days = str(runtime_in_days)\n",
    "seed = str(RNG_seed)\n",
    "npart= str(use_number_particles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree2km = 1.852*60.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct input / output paths etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_mask = mask_path / experiment_name / mesh_mask_filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldset_defintions(\n",
    "    list_of_filenames_U, list_of_filenames_V,\n",
    "    list_of_filenames_W, list_of_filenames_T,\n",
    "    mesh_mask\n",
    "):\n",
    "    \n",
    "    filenames = {'U': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_U},\n",
    "                 'V': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_V},\n",
    "                 'W': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_W},\n",
    "                 'T': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_T},\n",
    "                 'S': {'lon': (mesh_mask),\n",
    "                       'lat': (mesh_mask),\n",
    "                       'depth': list_of_filenames_W[0],\n",
    "                       'data': list_of_filenames_T}\n",
    "                }\n",
    "    \n",
    "    variables = {'U': 'vozocrtx',\n",
    "                 'V': 'vomecrty',\n",
    "                 'W': 'vovecrtz',\n",
    "                 'T': 'votemper',\n",
    "                 'S': 'vosaline'\n",
    "                }\n",
    "        \n",
    "    dimensions = {'U': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  # needs to be on f-nodes\n",
    "                  'V': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  # needs to be on f-nodes\n",
    "                  'W': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  # needs to be on f-nodes\n",
    "                  'T': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  # needs to be on t-nodes\n",
    "                  'S': {'lon': 'glamf', 'lat': 'gphif', 'depth': 'depthw',\n",
    "                        'time': 'time_counter'},  # needs to be on t-nodes\n",
    "                 }\n",
    "    \n",
    "#     indices = {\n",
    "#         'U': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat': range(sd_j1, sd_j2)},\n",
    "#         'V': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat': range(sd_j1, sd_j2)},\n",
    "#         'W': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat':range(sd_j1, sd_j2)},\n",
    "#         'T': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat':range(sd_j1, sd_j2)},\n",
    "#         'S': {'depth': range(sd_z1, sd_z2), 'lon': range(sd_i1, sd_i2), 'lat':range(sd_j1, sd_j2)}\n",
    "#     }    \n",
    "    \n",
    "    field_chunksizes = {'U': {'lon':('x', 1024), 'lat':('y',128), 'depth': ('depthw', 64),\n",
    "                        'time': ('time_counter',3)},  # needs to be on f-nodes\n",
    "                  'V': {'lon':('x', 1024), 'lat':('y',128), 'depth': ('depthw', 64),\n",
    "                        'time': ('time_counter',3)},  # needs to be on f-nodes\n",
    "                  'W': {'lon':('x', 1024), 'lat':('y',128), 'depth': ('depthw', 64),\n",
    "                        'time': ('time_counter',3)},  # needs to be on f-nodes\n",
    "                  'T': {'lon':('x', 1024), 'lat':('y',128), 'depth': ('depthw', 64),\n",
    "                        'time': ('time_counter',3)},  # needs to be on t-nodes\n",
    "                  'S': {'lon':('x', 1024), 'lat':('y',128), 'depth': ('depthw', 64),\n",
    "                        'time': ('time_counter',3)},  # needs to be on t-nodes\n",
    "                 }\n",
    "\n",
    "    return FieldSet.from_nemo(\n",
    "        filenames, variables, dimensions, \n",
    "#        indices=indices,\n",
    "        chunksize=field_chunksizes,  # = None for no chunking\n",
    "        mesh='spherical',\n",
    "        tracer_interp_method='cgrid_tracer'\n",
    "#         ,time_periodic=time_loop_period\n",
    "#         ,allow_time_extrapolation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fieldset(\n",
    "    data_path=data_path, experiment_name=experiment_name,\n",
    "    fname_U=fname_U, fname_V=fname_V, fname_W=fname_W, fname_T=fname_T,\n",
    "    mesh_mask = mesh_mask\n",
    "):\n",
    "    \n",
    "    files_U = list(sorted((data_path / experiment_name).glob(fname_U)))\n",
    "    files_V = list(sorted((data_path / experiment_name).glob(fname_V)))\n",
    "    files_W = list(sorted((data_path / experiment_name).glob(fname_W)))\n",
    "    files_T = list(sorted((data_path / experiment_name).glob(fname_T)))\n",
    "    \n",
    "    print(files_U)\n",
    "    \n",
    "    fieldset = fieldset_defintions(\n",
    "        files_U, files_V,\n",
    "        files_W, files_T, mesh_mask)\n",
    "\n",
    "    return fieldset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldset = create_fieldset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Virtual Particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add a couple of simple plotting routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_section_sdist():\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    u = np.array([p.uvel for p in pset]) * degree2km * 1000.0 * np.cos(np.radians(pset.lat))\n",
    "    v = np.array([p.vvel for p in pset]) * degree2km * 1000.0\n",
    "    section_index = np.searchsorted(lonlat.lon,pset.lon)-1\n",
    "    u_normal = v * lonlatdiff.costheta[section_index].data - u * lonlatdiff.sintheta[section_index].data\n",
    "    y = (pset.lat - lonlat.lat[section_index]) * degree2km\n",
    "    x = (pset.lon - lonlat.lon[section_index]) * degree2km*np.cos(np.radians(lonlat2mean.lat[section_index+1].data))\n",
    "    dist = np.sqrt(x**2 + y**2) + lonlatdiff.length_west[section_index].data\n",
    "    \n",
    "    \n",
    "    plt.scatter(\n",
    "        dist,\n",
    "        [p.depth for p in pset],\n",
    "        1,\n",
    "        u_normal,\n",
    "        cmap=co.cm.balance,vmin=-0.3,vmax=0.3\n",
    "    )\n",
    "    plt.ylim(1200,0)\n",
    "    plt.colorbar(label = r'normal velocity [$\\mathrm{m\\ s}^{-1}$]')\n",
    "    plt.xlabel('distance [km]')\n",
    "    plt.ylabel('depth [m]')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_section_lon():\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    u = np.array([p.uvel for p in pset]) * degree2km * 1000.0 * np.cos(np.radians(pset.lat))\n",
    "    v = np.array([p.vvel for p in pset]) * degree2km * 1000.0\n",
    "    section_index = np.searchsorted(lonlat.lon,pset.lon)-1\n",
    "    u_normal = v * lonlatdiff.costheta[section_index].data - u * lonlatdiff.sintheta[section_index].data\n",
    "    \n",
    "    plt.scatter(\n",
    "        [p.lon for p in pset],\n",
    "        [p.depth for p in pset],\n",
    "        1,\n",
    "        u_normal,\n",
    "        cmap=co.cm.balance,vmin=-0.3,vmax=0.3\n",
    "    )\n",
    "    plt.ylim(1200,0)\n",
    "    plt.colorbar(label = r'normal velocity [$\\mathrm{m\\ s}^{-1}$]');\n",
    "    plt.xlabel('longitude [$\\degree$E]')\n",
    "    plt.ylabel('depth [m]')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleParticle(JITParticle):\n",
    "    \"\"\"Add variables to the standard particle class.\n",
    "    \n",
    "    Particles will sample temperature and track the age of the particle.\n",
    "    Particles also have a flag `alive` that is 1 if the particle is alive and 0 otherwise.\n",
    "    Furthermore, we have a `speed_param` that scales the velocity with which particles can\n",
    "    swim towards the surface.\n",
    "\n",
    "    Note that we don't initialize temp from the actual data.\n",
    "    This speeds up particle creation, but might render initial data point less useful.\n",
    "    \"\"\"\n",
    "    temp = Variable('temp', dtype=np.float32, initial=-100)\n",
    "    salt = Variable('salt', dtype=np.float32, initial=-100)\n",
    "    uvel = Variable('uvel', dtype=np.float32, initial=0)\n",
    "    vvel = Variable('vvel', dtype=np.float32, initial=0)\n",
    "#    wvel = Variable('wvel', dtype=np.float32, initial=0)\n",
    "#     alive = Variable('alive', dtype=np.int32, initial=1)\n",
    "#     speed_param = Variable('speed_param', dtype=np.float32, initial=1)\n",
    "#     age = Variable('age', dtype=np.int32, initial=0, to_write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of particles with random initial positions\n",
    "\n",
    "We seed the RNG to be reproducible (and to be able to quickly create a second equivalent experiment with differently chosen compatible initial positions), and create arrays of random starting times, lats, lons, depths, and speed parameters (see kernel definitions below for details).\n",
    "\n",
    "Initially create points on 'rectangle'. Land points are removed later in a OceanParcels 'run' with runtime and timedelta zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First set up the piecewise section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlat = xr.Dataset(pd.read_csv(sectionPath / sectionFilename,delim_whitespace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlat.lon.attrs['long_name']='Longitude'\n",
    "lonlat.lat.attrs['long_name']='Latitude'\n",
    "lonlat.lon.attrs['standard_name']='longitude'\n",
    "lonlat.lat.attrs['standard_name']='latitude'\n",
    "lonlat.lon.attrs['units']='degrees_east'\n",
    "lonlat.lat.attrs['units']='degrees_north'\n",
    "\n",
    "lonlatdiff = lonlat.diff('dim_0')\n",
    "lonlat2mean= lonlat.rolling({'dim_0':2}).mean()\n",
    "\n",
    "lonlat.plot.scatter(x='lon',y='lat')\n",
    "lonlat2mean.plot.scatter(x='lon',y='lat')\n",
    "\n",
    "lonlatdiff = lonlatdiff.assign({'y':lonlatdiff['lat']*degree2km})\n",
    "lonlatdiff = lonlatdiff.assign({'x':lonlatdiff['lon']*degree2km*np.cos(np.radians(lonlat2mean.lat.data[1:]))})\n",
    "lonlatdiff=lonlatdiff.assign({'length':np.sqrt(lonlatdiff['x']**2+lonlatdiff['y']**2)})\n",
    "lonlatdiff=lonlatdiff.assign({'length_west':lonlatdiff.length.sum() - np.cumsum(lonlatdiff.length[::-1])[::-1]})\n",
    "lonlatdiff=lonlatdiff.assign({'costheta':lonlatdiff['x']/lonlatdiff['length']})\n",
    "lonlatdiff=lonlatdiff.assign({'sintheta':lonlatdiff['y']/lonlatdiff['length']})\n",
    "\n",
    "total_length = lonlatdiff.length.sum().data\n",
    "print(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlatdiff.length.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed particles uniform random along OSNAP section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RNG_seed)\n",
    "\n",
    "# define time of release for each particle relative to t0\n",
    "# can start each particle at a different time if required\n",
    "# here all start at time t_start.\n",
    "times = []\n",
    "lons = []\n",
    "lats = []\n",
    "depths = []\n",
    "\n",
    "# for subsect in range(lonlatdiff.length.shape[0]):\n",
    "for subsect in range(start_vertex,end_vertex):\n",
    "    \n",
    "    number_particles = int(create_number_particles*lonlatdiff.length[subsect]/total_length)\n",
    "    time = np.zeros(number_particles)\n",
    "    time += (t_start - t_0).total_seconds()\n",
    "\n",
    "    # start along a line from west to east\n",
    "\n",
    "    west_lat = lonlat.lat[subsect].data\n",
    "    west_lon = lonlat.lon[subsect].data\n",
    "    east_lat = lonlat.lat[subsect+1].data\n",
    "    east_lon = lonlat.lon[subsect+1].data\n",
    "    \n",
    "    lon = np.random.uniform(\n",
    "        low=west_lon, high = east_lon,\n",
    "        size=time.shape\n",
    "    )\n",
    "    lat = west_lat + ((lon - west_lon) * (east_lat - west_lat)/ (east_lon - west_lon))\n",
    "\n",
    "    # at depths from surface to max_release_depth\n",
    "\n",
    "    depth = np.random.uniform(\n",
    "        low=min_release_depth, high=max_release_depth,\n",
    "        size=time.shape\n",
    "    )\n",
    "    times.append(time)\n",
    "    lons.append(lon)\n",
    "    lats.append(lat)\n",
    "    depths.append(depth)\n",
    "\n",
    "    \n",
    "    \n",
    "time = np.concatenate(times)\n",
    "lon = np.concatenate(lons)\n",
    "lat = np.concatenate(lats)\n",
    "depth = np.concatenate(depths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build particle set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pset = ParticleSet(\n",
    "    fieldset=fieldset,\n",
    "    pclass=SampleParticle,\n",
    "    lat=lat,\n",
    "    lon=lon,\n",
    "#     speed_param=speed_param,\n",
    "    depth=depth,\n",
    "    time=time\n",
    "#    repeatdt = repeatdt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Created {len(pset)} particles.\")\n",
    "# display(pset[:5])\n",
    "# display(pset[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose custom kernel\n",
    "\n",
    "We'll create three additional kernels:\n",
    "- One Kernel adds velocity sampling\n",
    "- One Kernel adds temperature sampling\n",
    "- One kernel adds salinity sampling\n",
    "\n",
    "Then, we combine the builtin `AdvectionRK4_3D` kernel with these additional kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocity_sampling(particle, fieldset, time):\n",
    "    '''Sample velocity.'''\n",
    "    \n",
    "    (particle.uvel,particle.vvel) = fieldset.UV[time, particle.depth, particle.lat, particle.lon]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_sampling(particle, fieldset, time):\n",
    "    '''Sample temperature.'''\n",
    "    \n",
    "    particle.temp = fieldset.T[time, particle.depth, particle.lat, particle.lon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salinity_sampling(particle, fieldset, time):\n",
    "    '''Sample salinity.'''\n",
    "    \n",
    "    particle.salt = fieldset.S[time, particle.depth, particle.lat, particle.lon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_kernel = (\n",
    "    pset.Kernel(AdvectionRK4_3D)\n",
    "#     + pset.Kernel(temperature_sensitivity)\n",
    "     + pset.Kernel(temperature_sampling)\n",
    "     + pset.Kernel(salinity_sampling)\n",
    "     + pset.Kernel(velocity_sampling)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be able to handle errors during integration\n",
    "\n",
    "We have restricted our domain so in principle, particles could reach undefined positions.\n",
    "In that case, we want to just delete the particle (without forgetting its history)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeleteParticle(particle, fieldset, time):\n",
    "    particle.delete()\n",
    "\n",
    "\n",
    "recovery_cases = {\n",
    "    ErrorCode.ErrorOutOfBounds: DeleteParticle,\n",
    "    ErrorCode.Error: DeleteParticle,\n",
    "    ErrorCode.ErrorInterpolation: DeleteParticle\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with runtime=0 to initialise fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "pset.execute(\n",
    "    custom_kernel,\n",
    "     runtime=0,    \n",
    "#      dt=timedelta(minutes=0),      \n",
    "#      output_file=outputfile,\n",
    "     recovery=recovery_cases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_section_sdist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim unwanted points from ParticleSet\n",
    "\n",
    "Use initialised fields to remove land points. We test `temp == 0.0` (the mask value over land).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([p.temp for p in pset])\n",
    "# u = np.array([p.uvel for p in pset])\n",
    "# v = np.array([p.vvel for p in pset])\n",
    "pset.remove_indices(np.argwhere(t == 0).flatten())\n",
    "# pset.remove(np.argwhere(x * y * z == 0).flatten())\n",
    "print(len(pset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_section_sdist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test velocity normal to section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Velocity conversions from degrees lat/lon per second to m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([p.uvel for p in pset])\n",
    "v = np.array([p.vvel for p in pset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=u * degree2km * 1000.0 * np.cos(np.radians(pset.lat))\n",
    "v=v * degree2km * 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normal velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_index = np.searchsorted(lonlat.lon,pset.lon)-1\n",
    "u_normal = v * lonlatdiff.costheta[section_index].data - u * lonlatdiff.sintheta[section_index].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(u_normal).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove particles randomly with probability proportional to normal speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_random = np.random.rand(len(u_normal))*max_current\n",
    "pset.remove_indices(np.argwhere(abs(u_normal) < u_random).flatten())\n",
    "\n",
    "print(len(pset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_section_sdist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare output\n",
    "\n",
    "We define an output file and specify the desired output frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_filename = 'Parcels_IFFForwards_1m_June2016_2000.nc'\n",
    "npart = str(len(pset))\n",
    "output_filename = 'tracks_randomvel_'+sectionname+direction+year_str+month_str+'_N'+npart+'_D'+days+'_Rnd'+ seed+'.nc'\n",
    "outfile = outpath / output_filename\n",
    "\n",
    "print(outfile)\n",
    "outputfile = pset.ParticleFile(\n",
    "    name=outfile,\n",
    "    outputdt=timedelta(hours=outputdt_in_hours)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the experiment\n",
    "\n",
    "We'll evolve particles, log their positions and variables to the output buffer and finally export the output to a  the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "pset.execute(\n",
    "    custom_kernel,\n",
    "     runtime=timedelta(days=runtime_in_days),    \n",
    "     dt=timedelta(minutes=dt_in_minutes),      \n",
    "     output_file=outputfile,\n",
    "     recovery=recovery_cases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputfile.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parcels-container_2021.03.17-6c459b7]",
   "language": "python",
   "name": "conda-env-parcels-container_2021.03.17-6c459b7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
